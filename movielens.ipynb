{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MovieLens users and movies embaddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m162.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\r\n",
      "  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.1/7.1 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m0m\r\n",
      "\u001B[?25hCollecting tqdm (from sentence-transformers)\r\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\r\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\r\n",
      "  Downloading torch-2.0.1-cp39-none-macosx_11_0_arm64.whl (55.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.8/55.8 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision (from sentence-transformers)\r\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.24.3)\r\n",
      "Collecting scikit-learn (from sentence-transformers)\r\n",
      "  Using cached scikit_learn-1.2.2-cp39-cp39-macosx_12_0_arm64.whl (8.5 MB)\r\n",
      "Collecting scipy (from sentence-transformers)\r\n",
      "  Using cached scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl (28.9 MB)\r\n",
      "Collecting nltk (from sentence-transformers)\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m0m\r\n",
      "\u001B[?25hCollecting sentencepiece (from sentence-transformers)\r\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\r\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m224.5/224.5 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting filelock (from huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\r\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m160.1/160.1 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting requests (from huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.5/62.5 kB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\r\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\r\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting networkx (from torch>=1.6.0->sentence-transformers)\r\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m14.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\r\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\r\n",
      "  Downloading regex-2023.5.5-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m288.9/288.9 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\r\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_12_0_arm64.whl (3.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.9/3.9 MB\u001B[0m \u001B[31m15.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting click (from nltk->sentence-transformers)\r\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.6/96.6 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting joblib (from nltk->sentence-transformers)\r\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\r\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers)\r\n",
      "  Using cached Pillow-9.5.0-cp39-cp39-macosx_11_0_arm64.whl (3.1 MB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m123.0/123.0 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m123.2/123.2 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.4.0->sentence-transformers)\r\n",
      "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m157.0/157.0 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m19.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=c288ae4ca44a25ba0ee2758eeac5b22bfd4acbfd5c6c0b977c57e77210e8a5b2\r\n",
      "  Stored in directory: /Users/alekseykomissarenko/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, urllib3, tqdm, threadpoolctl, sympy, scipy, regex, pillow, networkx, joblib, fsspec, filelock, click, charset-normalizer, certifi, torch, scikit-learn, requests, nltk, torchvision, huggingface-hub, transformers, sentence-transformers\r\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 click-8.1.3 filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.14.1 joblib-1.2.0 mpmath-1.3.0 networkx-3.1 nltk-3.8.1 pillow-9.5.0 regex-2023.5.5 requests-2.30.0 scikit-learn-1.2.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.11.1 threadpoolctl-3.1.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 tqdm-4.65.0 transformers-4.29.0 urllib3-2.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:33:27.449551Z",
     "start_time": "2023-05-10T17:32:40.256822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data load and preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем ссылку на датасет и словарь, в котором будут храниться таблицы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "datasets = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:35:59.155683Z",
     "start_time": "2023-05-10T17:35:59.143537Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "zipfile.namelist() используется для получения списка имен файлов в архиве, затем отбираются только те файлы, которые заканчиваются на '.csv'. Для каждого .csv файла используется pandas.read_csv() для загрузки данных в датафрейм, затем этот датафрейм добавляется в словарь datasets"
   ],
   "metadata": {
    "id": "ba_6YUgSS9Vj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with urllib.request.urlopen(url) as url_file:\n",
    "  with zipfile.ZipFile(io.BytesIO(url_file.read())) as zip_file:\n",
    "    for file_name in zip_file.namelist():\n",
    "      if file_name.endswith('.csv'):\n",
    "        with zip_file.open(file_name) as data_file:\n",
    "          dataset = pd.read_csv(data_file)\n",
    "          datasets[file_name] = dataset"
   ],
   "metadata": {
    "id": "JgHLAtQRTp4J",
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:27.845959Z",
     "start_time": "2023-05-10T17:36:01.107426Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "datasets.keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td4ku1tHVFjj",
    "outputId": "cf1ed1cb-e09f-4adc-e048-7c86b98b150b",
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:29.368822Z",
     "start_time": "2023-05-10T17:36:29.359134Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['ml-latest/links.csv', 'ml-latest/tags.csv', 'ml-latest/genome-tags.csv', 'ml-latest/ratings.csv', 'ml-latest/genome-scores.csv', 'ml-latest/movies.csv'])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загружаем все датафреймы в отельные переменные для удобства"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "links = datasets['ml-latest/links.csv']\n",
    "tags = datasets['ml-latest/tags.csv']\n",
    "genome_tags = datasets['ml-latest/genome-tags.csv']\n",
    "ratings = datasets['ml-latest/ratings.csv']\n",
    "genome_scores = datasets['ml-latest/genome-scores.csv']\n",
    "movies = datasets['ml-latest/movies.csv']"
   ],
   "metadata": {
    "id": "grw_apiTVSyP",
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:31.159350Z",
     "start_time": "2023-05-10T17:36:31.146128Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так как нас интересуют пользователи и фильмы, объединяем таблицы с помощью айдишника фильма"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.merge(ratings, movies, on='movieId')\n",
    "data"
   ],
   "metadata": {
    "id": "5vqM_FgsdJPn",
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:35.387388Z",
     "start_time": "2023-05-10T17:36:31.882033Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keras solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для построения нейронки воспользуемся моделью \"Embedding\", которая позволит нам получить векторное представление для каждого пользователя и фильма. Это достигается путем использования слоя \"Embedding\" в модели, который принимает номер пользователя или фильма и возвращает векторное представление для этих данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Количество уникальных пользователей и фильмов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_users = len(data.userId.unique())\n",
    "n_movies = len(data.movieId.unique())"
   ],
   "metadata": {
    "id": "45A_0-RYd4IV",
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:36.192306Z",
     "start_time": "2023-05-10T17:36:35.932131Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Входные данные для пользователей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_input = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=n_users, output_dim=50, name='user_embedding')(user_input)\n",
    "user_flatten = Flatten(name='user_flatten')(user_embedding)"
   ],
   "metadata": {
    "id": "DlZ16mzIebY-"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Входные данные для фильмов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "movie_input = Input(shape=(1,), name='movie_input')\n",
    "movie_embedding = Embedding(input_dim=n_movies, output_dim=50, name='movie_embedding')(movie_input)\n",
    "movie_flatten = Flatten(name='movie_flatten')(movie_embedding)"
   ],
   "metadata": {
    "id": "RiDegUazeoNX"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Объединяем векторы пользователей и фильмов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dot = Dot(name='dot', axes=1)([user_flatten, movie_flatten])"
   ],
   "metadata": {
    "id": "f_fAoAtFfEpw"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Добавляем скрытый слой"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dense = Dense(128, activation='relu')(dot)"
   ],
   "metadata": {
    "id": "TOyN2dCekhO6"
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Добавляем выходной слой"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "output = Dense(1, activation='linear')(dense)"
   ],
   "metadata": {
    "id": "auV837eCkrPP"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Воспользуемся метрикой RMSE, которая является стандартной метрикой для задач регрессии. Эта метрика показывает насколько отличаются предсказанные значения от фактических. В нашем случае, метрика покажет насколько отличается рейтинг, предсказанный моделью, от реального рейтинга"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwCARVf1fU9N",
    "outputId": "aa0c97d9-1134-4ce5-e052-abd062a2adf1"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " movie_input (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)     (None, 1, 50)        14161400    ['user_input[0][0]']             \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding)    (None, 1, 50)        2694450     ['movie_input[0][0]']            \n",
      "                                                                                                  \n",
      " user_flatten (Flatten)         (None, 50)           0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " movie_flatten (Flatten)        (None, 50)           0           ['movie_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['user_flatten[0][0]',           \n",
      "                                                                  'movie_flatten[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          256         ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,856,235\n",
      "Trainable params: 16,856,235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Стандартно разделяем на трейн/тест"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train, test = train_test_split(data, test_size=0.2)"
   ],
   "metadata": {
    "id": "84j2XHYGfkJC"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучаем модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    [train.userId, train.movieId],\n",
    "    train.rating,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MR2HOp-gUjq",
    "outputId": "d234c394-5544-49ac-e96f-9bf08bfdd9b6"
   },
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "312227/312227 [==============================] - 2358s 7ms/step - loss: 1.0402 - val_loss: 1.0094\n",
      "Epoch 2/5\n",
      "312227/312227 [==============================] - 2329s 7ms/step - loss: 0.9627 - val_loss: 0.9822\n",
      "Epoch 3/5\n",
      "312227/312227 [==============================] - 2324s 7ms/step - loss: 0.9085 - val_loss: 0.9683\n",
      "Epoch 4/5\n",
      "312227/312227 [==============================] - 2308s 7ms/step - loss: 0.8523 - val_loss: 0.9653\n",
      "Epoch 5/5\n",
      "312227/312227 [==============================] - 2297s 7ms/step - loss: 0.8209 - val_loss: 0.9675\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss = model.evaluate([test.userId, test.movieId], test.rating)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm-7dmmzg4Fv",
    "outputId": "9c02bafa-fc1e-4d00-a81e-55c466e76133"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "173460/173460 [==============================] - 367s 2ms/step - loss: 0.9666\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем эмбеддинги"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_embeddings = model.get_layer('user_embedding').get_weights()[0]\n",
    "movie_embeddings = model.get_layer('movie_embedding').get_weights()[0]"
   ],
   "metadata": {
    "id": "WvyNf0qOR5IP"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь мы можем получить эмбеддинг любого пользователя или фильма для дальнейшего построения рекомендательной системы. Примером такой системы могут послужить методы совместной фильтрации или фильтрации на основе содержимого"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_embeddings[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBIJyrGxVCPw",
    "outputId": "36540817-0b5d-4635-9edf-beca5234e764"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.02779937,  0.00534084,  0.04119035,  0.0403241 ,  0.04175929,\n",
       "        0.00733225,  0.02360013,  0.04125011,  0.01223646, -0.04585896,\n",
       "       -0.03797797,  0.04649505,  0.01777902,  0.02611933, -0.03935809,\n",
       "        0.00966378,  0.02512116,  0.00511296, -0.04630522,  0.03667393,\n",
       "        0.0027166 , -0.04555022, -0.01216433,  0.00612092,  0.04418515,\n",
       "        0.03996499, -0.02412491, -0.03723481, -0.00687162,  0.01643166,\n",
       "       -0.04190822, -0.02582397,  0.00117594, -0.02756792, -0.0120428 ,\n",
       "       -0.02693969, -0.00619071, -0.00637976, -0.04316893,  0.01887869,\n",
       "       -0.01709574,  0.00214823, -0.04281486, -0.01752869,  0.04286965,\n",
       "       -0.03691769, -0.04671529,  0.01090802, -0.00251915,  0.02390409],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "movie_embeddings[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2R5SOVVoU_HV",
    "outputId": "9b36cbf5-62b8-4485-ba9e-e1a7a45b7dd6"
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.04293933,  0.03131613, -0.01073663, -0.03731848,  0.03326725,\n",
       "        0.04103079,  0.00210664, -0.03034762,  0.01994571,  0.04412626,\n",
       "        0.00429127,  0.03168922, -0.03301521, -0.03680787,  0.03625906,\n",
       "        0.03576152,  0.01582966, -0.02679781, -0.04903481, -0.00113448,\n",
       "       -0.01390636, -0.04822518,  0.00497645, -0.02654135, -0.00971418,\n",
       "       -0.0454193 , -0.01934587,  0.039131  , -0.04413257,  0.0487512 ,\n",
       "       -0.03569707, -0.03424858,  0.01815159,  0.03038087, -0.021184  ,\n",
       "       -0.036779  , -0.01747854, -0.00431689, -0.00383417,  0.02753878,\n",
       "        0.02891609,  0.00415385,  0.03766796,  0.02432663, -0.01944426,\n",
       "        0.01731909, -0.02475315, -0.04089544, -0.01920109,  0.01414583],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SentenceTransformer solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Другой метод решения – использование Bert Universal Sentence Encoder для получения эмбеддинга тайтлов фильмов. После мы можем посчитать средний эмбединг всех просмотренных пользователем фильмов с учетом их рейтинга и присвоить их ему. Дальше на основе этого можно рекомендовать фильмы с похожими эмбеддингами"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем уникальные названия фильмов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Three Colors: Blue (Trois couleurs: Bleu) (1993)',\n       'Kalifornia (1993)', \"Weekend at Bernie's (1989)\", ...,\n       'Hotline (2014)', 'Barnum! (1986)',\n       'Paul Taylor Creative Domain (2014)'], dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_titles = data['title'].unique()\n",
    "unique_titles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:36:52.752947Z",
     "start_time": "2023-05-10T17:36:52.098270Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем словарь с парами названия фильма: эмбеддинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "title_encodings = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T20:28:45.291629Z",
     "start_time": "2023-05-10T20:28:45.290470Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем трансформер"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)7729f/.gitattributes:   0%|          | 0.00/1.22k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1434d830f324dcaaca7854c6729baea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "307303d1b4ff41f987aad7867dc43cb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)a63d77729f/README.md:   0%|          | 0.00/1.85k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c26090e836504a02b3c1671e60879adb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)3d77729f/config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba370dc19e9442df94997594f6f6accb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "317baab0c7684b1aa9a8132c37bdaebb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.89G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cde9c4099289423bae2f14f65faf0188"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7be24359a30644a596f0ece541c3b61d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c87f760d8df1407f891d2d41b07ba2d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)7729f/tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e8917cc68ae4835b25d1081f7d13f42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd49cbf1adfb486a8c27e5f57f198f28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)a63d77729f/vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90c3e054dbac46c781dca83ea41ff6b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)d77729f/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56b65a8df6464807a87e14b96d926c0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/alekseykomissarenko/.cache/torch/sentence_transformers/sentence-transformers_use-cmlm-multilingual/ were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/use-cmlm-multilingual')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T17:39:03.431559Z",
     "start_time": "2023-05-10T17:37:20.146536Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее получаем эмбеддинги для каждого уникального названия фильма"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/53817 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad1f0efcf7f14613a0589374c8afb539"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(unique_titles))):\n",
    "  encoding = model.encode(unique_titles[i])\n",
    "  title_encodings[unique_titles[i]] = encoding"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-10T17:39:07.037297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/16378 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ec55e37eb8c4ac3be70a93b4f8ff03b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(37439, len(unique_titles))):\n",
    "    encoding = model.encode(unique_titles[i])\n",
    "    title_encodings[unique_titles[i]] = encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T18:52:16.878326Z",
     "start_time": "2023-05-10T18:36:54.927887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "53817"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_encodings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T20:14:50.593419Z",
     "start_time": "2023-05-10T20:14:50.574096Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаем колонку с эмбедингами"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "encodings_column = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T20:22:08.412128Z",
     "start_time": "2023-05-10T20:22:08.406418Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Записываем эмбеддинг, если название фильма в строке совпадает с ключом словаря эмбеддингов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/27753444 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2140b24892b4291a970e4213def6e0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(data))):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m title_encodings:\n\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;241m==\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m]\u001B[49m:\n\u001B[1;32m      4\u001B[0m             encodings_column\u001B[38;5;241m.\u001B[39mappend(encoding)\n",
      "File \u001B[0;32m~/Desktop/PyCharm/MovieLens/venv/lib/python3.9/site-packages/pandas/core/series.py:993\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m--> 993\u001B[0m     \u001B[43mcheck_dict_or_set_indexers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    994\u001B[0m     key \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    996\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mEllipsis\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for row in tqdm(range(len(data))):\n",
    "    for encoding in title_encodings:\n",
    "        if encoding == data['title'][row]:\n",
    "            encodings_column.append(encoding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T20:22:21.851570Z",
     "start_time": "2023-05-10T20:22:08.800780Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "К сожалению, не успел по времени, поэтому дальнейшее решение по плану продолжить не удалось"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
